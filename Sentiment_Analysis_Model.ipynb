{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2DRPEbAi2I3"
      },
      "source": [
        "## Setting up the environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WuJmi1-UUum"
      },
      "source": [
        "# getting spark ready\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FJccZ5GeYQs"
      },
      "source": [
        "#importing modules\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.ml.feature import HashingTF, Tokenizer, StopWordsRemover\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jAQE0PkVFvt"
      },
      "source": [
        "# creating spark session\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34iCXzyqjHLL"
      },
      "source": [
        "## Loading and Viewing the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnPs3naQWfBe"
      },
      "source": [
        "# loading tweets data\n",
        "tweets = spark.read.csv(\"/content/drive/MyDrive/Sentiment Analysis/tweets.csv\",  inferSchema=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNXigAtTbt8B",
        "outputId": "11073865-c946-4b4d-d192-f028c7c6bb1e"
      },
      "source": [
        "tweets.show(truncate=False, n=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
            "|_c0|_c1       |_c2                         |_c3     |_c4            |_c5                                                                                                                |\n",
            "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
            "|0  |1467810369|Mon Apr 06 22:19:45 PDT 2009|NO_QUERY|_TheSpecialOne_|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D|\n",
            "|0  |1467810672|Mon Apr 06 22:19:49 PDT 2009|NO_QUERY|scotthamilton  |is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!    |\n",
            "|0  |1467810917|Mon Apr 06 22:19:53 PDT 2009|NO_QUERY|mattycus       |@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds                          |\n",
            "|0  |1467811184|Mon Apr 06 22:19:57 PDT 2009|NO_QUERY|ElleCTF        |my whole body feels itchy and like its on fire                                                                     |\n",
            "|0  |1467811193|Mon Apr 06 22:19:57 PDT 2009|NO_QUERY|Karoli         |@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.     |\n",
            "+---+----------+----------------------------+--------+---------------+-------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LySEiAoHcQtp"
      },
      "source": [
        "# we only need c0 and c5 for our model tweets and label\n",
        "data = tweets.select(col(\"_c5\").alias(\"tweet\"), col(\"_c0\").cast(\"Int\").alias(\"label\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eje6144ud7aV",
        "outputId": "47b6a34e-d4fc-470d-a9af-11d3d5ab6910"
      },
      "source": [
        "data.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|               tweet|label|\n",
            "+--------------------+-----+\n",
            "|@switchfoot http:...|    0|\n",
            "|is upset that he ...|    0|\n",
            "|@Kenichan I dived...|    0|\n",
            "|my whole body fee...|    0|\n",
            "|@nationwideclass ...|    0|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41qnviFFjMcE"
      },
      "source": [
        "## Preprocesing the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ4rjbO8ehfv",
        "outputId": "074f275b-a60b-425f-8127-d58c0659f8ea"
      },
      "source": [
        "# Dividing data to train and test\n",
        "df = data.randomSplit([0.7, 0.3]) \n",
        "train_df = df[0]\n",
        "test_df = df[1] \n",
        "train_df.count(), test_df.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1119935, 480065)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPrPEFSyip3y"
      },
      "source": [
        "# creating a function to preprocess data for our model\n",
        "def preprocess(data):\n",
        "\n",
        "  # first we need to form a list of words (tokenize)\n",
        "  tokenizer = Tokenizer(inputCol=\"tweet\", outputCol=\"tweetTokens\")\n",
        "  tokenized_data = tokenizer.transform(data)\n",
        "\n",
        "  # second we need to remove stop words \n",
        "  swr = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol=\"withoutStopWords\")\n",
        "  swr_data = swr.transform(tokenized_data)\n",
        "  \n",
        "  # third we will convert our list of words to numeric features using hash transformer\n",
        "  hash_transformer = HashingTF(inputCol=swr.getOutputCol(), outputCol=\"features\")\n",
        "  hashed_data = hash_transformer.transform(swr_data)\n",
        "\n",
        "  preprocessed_data = hashed_data.select('features', 'label')\n",
        "\n",
        "  return preprocessed_data\n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nbLOTxXuTta"
      },
      "source": [
        "train_data = preprocess(train_df)\n",
        "test_data = preprocess(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nAR6HPywUQq",
        "outputId": "70e6a483-5103-4b67-d672-694c6120ab2e"
      },
      "source": [
        "train_data.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|(262144,[76764,23...|    0|\n",
            "|(262144,[23825,74...|    0|\n",
            "|(262144,[89833,16...|    0|\n",
            "|(262144,[1512,125...|    0|\n",
            "|(262144,[61899,23...|    0|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzNDHXFF2hoX"
      },
      "source": [
        "# Training  models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ig090dXD2kbW"
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression, NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# creating evaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
        "                                              metricName=\"accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T3GZnpX_1P2"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SqqtOjt-9bP"
      },
      "source": [
        "# fitting model\n",
        "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
        "nb_model = nb.fit(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIR3oaYwAAnn",
        "outputId": "546ccc56-7485-404b-af5b-73f49a44d7e9"
      },
      "source": [
        "# evaluating model\n",
        "nb_predictions = nb_model.transform(test_data)\n",
        "nb_accuracy = evaluator.evaluate(nb_predictions)\n",
        "print(str(nb_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.385841500630123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3OnPLKa9ZkO"
      },
      "source": [
        "## Logestic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmoPQYZd9Yum"
      },
      "source": [
        "# fitting model\n",
        "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10, regParam=0.3)\n",
        "lr_model = lr.fit(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d79P3nT-IFQ",
        "outputId": "5d1a926b-81e6-41aa-dc25-a461e516fdc3"
      },
      "source": [
        "# evaluating model\n",
        "lr_predictions = lr_model.transform(test_data)\n",
        "lr_accuracy = evaluator.evaluate(lr_predictions)\n",
        "print(str(lr_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7411267224230053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPvUzryiOQxA"
      },
      "source": [
        "As Logestic regression scored higher we will proceed with it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9c-WNpTErph"
      },
      "source": [
        "# saving lr model\n",
        "lr_model.save(\"/content/drive/MyDrive/Sentiment Analysis/lr\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}